\chapter{Conclusion}
\label{cha:conclusion}
The main goal of this thesis is to present a novel perspective on training deep neural networks, using techniques commonly used in control theory. Training a neural network, which is a constrained nonlinear program, is reformulated into an Optimal Control Problem. The classical algorithm of gradient descent using backpropagation can be seen as a "single shooting" approach in control theory. In this thesis the "multiple shooting" approach is investigated as an alternative, as this is commonly used for highly nonlinear problems.

Firstly the method is implemented in MATLAB using a very general optimization function \texttt{fmincon}, proving that the new approach is feasible. In a comparative test against a gradient descent algorithm, the new method converged 16 out of 20 times, while the gradient descent algorithm always converged. The classical algorithm is also much faster.

In the next step an Augmented Lagrangian framework from a recent paper is selected and adapted to solve the OCP. The least squares problem at the heart of this algorithm is solved using a Trust Region Reflective solver implemented in \texttt{scipy}. The Jacobian for this solver is analytically derived and numerically verified.

Finally the novel algorithm is tested against ADAM, an industry standard backpropagation method. For a small test problem which is difficult to train for classical gradient descent methods, the new algorithm converges in 46 out of 60 training runs, while ADAM converges only 14 out of 60 runs. For this test problem the new algorithm also has a shorter running time. However the running time and memory costs scale quadratically with the data set size. When compared for a time series prediction problem on the Santa Fe competition dataset, ADAM showed better test performance. The prediction made by the network trained by ADAM had an MSE of $9.100e^{-2}$ while the network trained by ALM showed an MSE of $8.288e^{-1}$. Because this problem is much larger in terms of dataset size and network size, ALM took on average 1201s to finish, while ADAM needed 20.9s.

The novel algorithm shows promising results, but so far this approach is limited by the size of the dataset used for training. Implementing a mini-batch training mode could address this limitation. For the problem of "bad" local minima, the new approach shows better performance, as seen in the first test case. However in larger neural networks, experts suspect local minima usually have comparable performance to the global minimum \cite{Goodfellow-et-al-2016}, as confirmed by the second, larger test case, where neither algorithm is hindered by "bad" local minima. In future research the new approach should be adapted to other loss functions besides the mean squared error loss, which would allow it to be more widely applicable.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
